{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5cd210-33ba-47c5-ac4f-cab5f606c168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:21:45.931516Z",
     "iopub.status.busy": "2023-09-24T19:21:45.931107Z",
     "iopub.status.idle": "2023-09-24T19:21:52.564178Z",
     "shell.execute_reply": "2023-09-24T19:21:52.563371Z",
     "shell.execute_reply.started": "2023-09-24T19:21:45.931486Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "310c1576-86c0-4ca6-afb3-ef360cfac5af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:29:28.868265Z",
     "iopub.status.busy": "2023-09-24T17:29:28.866915Z",
     "iopub.status.idle": "2023-09-24T17:29:29.296308Z",
     "shell.execute_reply": "2023-09-24T17:29:29.295323Z",
     "shell.execute_reply.started": "2023-09-24T17:29:28.868219Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Den4ikAI--russian_dialogues-2f0e674e933ff89a\n",
      "Reusing dataset json (/root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf99428881ac4ffbbc20128c4a7a85e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('Den4ikAI/russian_dialogues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da5a49e2-3c22-40ff-a2a5-70678975f3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:29:33.950207Z",
     "iopub.status.busy": "2023-09-24T17:29:33.949768Z",
     "iopub.status.idle": "2023-09-24T17:29:34.518146Z",
     "shell.execute_reply": "2023-09-24T17:29:34.517055Z",
     "shell.execute_reply.started": "2023-09-24T17:29:33.950179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-ecba1f789bb6e582.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-5fc2dd5f7c22d453.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Den4ikAI___json/Den4ikAI--russian_dialogues-2f0e674e933ff89a/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-928b7c7c52b925b5.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.class_encode_column('relevance')\n",
    "dataset = dataset.rename_column('relevance', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0258bfb-7369-42ba-83ab-3a619dbb0ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:29:37.990729Z",
     "iopub.status.busy": "2023-09-24T17:29:37.990315Z",
     "iopub.status.idle": "2023-09-24T17:29:41.077627Z",
     "shell.execute_reply": "2023-09-24T17:29:41.076484Z",
     "shell.execute_reply.started": "2023-09-24T17:29:37.990702Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(\n",
    "    test_size=0.05,\n",
    "    shuffle=True,\n",
    "    stratify_by_column='labels',\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5140729-440a-4317-83ec-b20a98d05a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:29:43.346495Z",
     "iopub.status.busy": "2023-09-24T17:29:43.345948Z",
     "iopub.status.idle": "2023-09-24T17:29:46.609169Z",
     "shell.execute_reply": "2023-09-24T17:29:46.607711Z",
     "shell.execute_reply.started": "2023-09-24T17:29:43.346456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac620cfdfd643fb9da087954f9dca98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(\n",
    "    lambda example: type(example['question']) is str and type(example['answer']) is str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96099c22-b4fc-442f-890d-47582f1b7ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:29:46.676516Z",
     "iopub.status.busy": "2023-09-24T17:29:46.676168Z",
     "iopub.status.idle": "2023-09-24T17:29:49.920047Z",
     "shell.execute_reply": "2023-09-24T17:29:49.918688Z",
     "shell.execute_reply.started": "2023-09-24T17:29:46.676490Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Den4ikAI/ruBert-base-qa-ranker'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ee458ef-04c7-4227-964d-9317423b1d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:29:49.922454Z",
     "iopub.status.busy": "2023-09-24T17:29:49.922051Z",
     "iopub.status.idle": "2023-09-24T17:29:50.124570Z",
     "shell.execute_reply": "2023-09-24T17:29:50.123440Z",
     "shell.execute_reply.started": "2023-09-24T17:29:49.922397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd44446d-50bb-408d-90c5-a8adef8251f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:29:54.749449Z",
     "iopub.status.busy": "2023-09-24T17:29:54.748718Z",
     "iopub.status.idle": "2023-09-24T17:29:54.756005Z",
     "shell.execute_reply": "2023-09-24T17:29:54.754724Z",
     "shell.execute_reply.started": "2023-09-24T17:29:54.749409Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenization(example):\n",
    "    return tokenizer(\n",
    "        '[CLS]' + example['question'] + '[RESPONSE_TOKEN]' + example['answer'],\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        add_special_tokens=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf97d650-e139-4e96-885a-9b0188d1fbab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:08:36.180081Z",
     "iopub.status.busy": "2023-09-24T18:08:36.179734Z",
     "iopub.status.idle": "2023-09-24T18:08:36.222512Z",
     "shell.execute_reply": "2023-09-24T18:08:36.221482Z",
     "shell.execute_reply.started": "2023-09-24T18:08:36.180055Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test = dataset.select(indices=range(5000))\n",
    "dataset_pruning = dataset.select(indices=range(5000, 15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08c97598-6516-493d-ab44-e6515cd483bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:09:02.813110Z",
     "iopub.status.busy": "2023-09-24T18:09:02.812727Z",
     "iopub.status.idle": "2023-09-24T18:09:13.203511Z",
     "shell.execute_reply": "2023-09-24T18:09:13.202492Z",
     "shell.execute_reply.started": "2023-09-24T18:09:02.813083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac224d0840e4ba2b806cc1f901c10ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6190bfcee69a4111aa5c0c32d97a1194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_test = dataset_test.map(tokenization, batched=False)\n",
    "dataset_pruning = dataset_pruning.map(tokenization, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b456c69a-941e-4cfd-a669-243e4b4bc4df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:09:41.961079Z",
     "iopub.status.busy": "2023-09-24T18:09:41.960659Z",
     "iopub.status.idle": "2023-09-24T18:09:41.968559Z",
     "shell.execute_reply": "2023-09-24T18:09:41.967254Z",
     "shell.execute_reply.started": "2023-09-24T18:09:41.961051Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "dataset_pruning.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cec014c5-9ca1-4732-a311-5daa411890be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:09:43.767468Z",
     "iopub.status.busy": "2023-09-24T18:09:43.767036Z",
     "iopub.status.idle": "2023-09-24T18:09:43.771812Z",
     "shell.execute_reply": "2023-09-24T18:09:43.770926Z",
     "shell.execute_reply.started": "2023-09-24T18:09:43.767440Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4017ce0-9fe2-4065-a177-c806b753a332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:13:55.594080Z",
     "iopub.status.busy": "2023-09-24T18:13:55.593157Z",
     "iopub.status.idle": "2023-09-24T18:13:55.598708Z",
     "shell.execute_reply": "2023-09-24T18:13:55.597520Z",
     "shell.execute_reply.started": "2023-09-24T18:13:55.594052Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eec253e-1916-48ff-96d8-a3c71458567a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:13:58.513819Z",
     "iopub.status.busy": "2023-09-24T18:13:58.513316Z",
     "iopub.status.idle": "2023-09-24T18:13:58.521016Z",
     "shell.execute_reply": "2023-09-24T18:13:58.519490Z",
     "shell.execute_reply.started": "2023-09-24T18:13:58.513783Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset_test, \n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "pruning_dataloader = DataLoader(\n",
    "    dataset_pruning, \n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2204e44-e70f-449a-a20a-cfdf9cfaa7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:13:54.970169Z",
     "iopub.status.busy": "2023-09-24T19:13:54.968781Z",
     "iopub.status.idle": "2023-09-24T19:13:54.981126Z",
     "shell.execute_reply": "2023-09-24T19:13:54.979964Z",
     "shell.execute_reply.started": "2023-09-24T19:13:54.970116Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_with_model(model, dataloader, max_idx=None):\n",
    "    preds = []\n",
    "    facts = []\n",
    "\n",
    "    for idx, batch in tqdm(enumerate(dataloader), total=max_idx if max_idx else len(dataloader)):\n",
    "        facts.append(batch.labels.cpu().numpy())\n",
    "        batch = batch.to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(\n",
    "                input_ids=batch.input_ids,\n",
    "                attention_mask=batch.attention_mask,\n",
    "                token_type_ids=batch.token_type_ids\n",
    "            )\n",
    "        preds.append(torch.sigmoid(pred.logits).cpu().numpy())\n",
    "        \n",
    "        if idx == max_idx:\n",
    "            break\n",
    "\n",
    "    facts = np.concatenate(facts)\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return facts, preds\n",
    "\n",
    "\n",
    "def evaluate_model(model, dev_dataloader):\n",
    "    facts, preds = predict_with_model(model, dev_dataloader)\n",
    "    roc_score = roc_auc_score(facts, preds[:, 0])\n",
    "    return roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d3ba0d-b861-43a8-acb6-768449219b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T00:06:47.100013Z",
     "iopub.status.busy": "2023-09-24T00:06:47.099483Z",
     "iopub.status.idle": "2023-09-24T00:10:15.068228Z",
     "shell.execute_reply": "2023-09-24T00:10:15.067185Z",
     "shell.execute_reply.started": "2023-09-24T00:06:47.099972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e872c2acf1d4c969882b9991f2c10f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score = evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98315577-63c8-4733-ac1c-b6d16f308898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T00:10:15.073724Z",
     "iopub.status.busy": "2023-09-24T00:10:15.073497Z",
     "iopub.status.idle": "2023-09-24T00:10:15.078667Z",
     "shell.execute_reply": "2023-09-24T00:10:15.077680Z",
     "shell.execute_reply.started": "2023-09-24T00:10:15.073698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Area Under ROC Curve is 0.9695577994975315 before quantization\n"
     ]
    }
   ],
   "source": [
    "print(f'Dev Area Under ROC Curve is {roc_auc_score} before quantization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718d0148-f4d5-4da9-ba0a-9717b4a784a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T00:10:15.082839Z",
     "iopub.status.busy": "2023-09-24T00:10:15.082614Z",
     "iopub.status.idle": "2023-09-24T00:10:15.140902Z",
     "shell.execute_reply": "2023-09-24T00:10:15.139930Z",
     "shell.execute_reply.started": "2023-09-24T00:10:15.082815Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark_args = PyTorchBenchmarkArguments(\n",
    "    models=[MODEL_NAME],\n",
    "    training=False,\n",
    "    inference=True,\n",
    "    sequence_lengths=[8,128,256,512],\n",
    "    batch_sizes=[1,32,64],\n",
    "    multi_process=False,\n",
    "    cuda=True,\n",
    "    speed=True,\n",
    ")\n",
    "\n",
    "benchmark = PyTorchBenchmark(benchmark_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84d82589-ff06-4131-b15b-43086bca05b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:20:38.788733Z",
     "iopub.status.busy": "2023-09-24T19:20:38.788356Z",
     "iopub.status.idle": "2023-09-24T19:20:44.041142Z",
     "shell.execute_reply": "2023-09-24T19:20:44.039417Z",
     "shell.execute_reply.started": "2023-09-24T19:20:38.788691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: py3nvml in /usr/local/lib/python3.9/dist-packages (0.2.7)\n",
      "Requirement already satisfied: xmltodict in /usr/local/lib/python3.9/dist-packages (from py3nvml) (0.13.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install py3nvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "644377fb-76e9-492f-a2e9-7e52d31b623c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T00:10:15.144447Z",
     "iopub.status.busy": "2023-09-24T00:10:15.144190Z",
     "iopub.status.idle": "2023-09-24T00:15:06.140491Z",
     "shell.execute_reply": "2023-09-24T00:15:06.139418Z",
     "shell.execute_reply.started": "2023-09-24T00:10:15.144421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1\n",
      "\n",
      "====================       INFERENCE - SPEED - RESULT       ====================\n",
      "--------------------------------------------------------------------------------\n",
      "          Model Name             Batch Size     Seq Length     Time in s   \n",
      "--------------------------------------------------------------------------------\n",
      "Den4ikAI/ruBert-base-qa-ranker       1               8             0.009     \n",
      "Den4ikAI/ruBert-base-qa-ranker       1              128            0.009     \n",
      "Den4ikAI/ruBert-base-qa-ranker       1              256            0.011     \n",
      "Den4ikAI/ruBert-base-qa-ranker       1              512            0.019     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32              8             0.011     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32             128            0.135     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32             256            0.365     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32             512            0.765     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64              8             0.018     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64             128            0.349     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64             256            0.709     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64             512            1.578     \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================      INFERENCE - MEMORY - RESULT       ====================\n",
      "--------------------------------------------------------------------------------\n",
      "          Model Name             Batch Size     Seq Length    Memory in MB \n",
      "--------------------------------------------------------------------------------\n",
      "Den4ikAI/ruBert-base-qa-ranker       1               8              3771     \n",
      "Den4ikAI/ruBert-base-qa-ranker       1              128             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       1              256             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       1              512             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32              8              3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32             128             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32             256             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       32             512             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64              8              3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64             128             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64             256             3775     \n",
      "Den4ikAI/ruBert-base-qa-ranker       64             512             4543     \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = benchmark.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71b355f7-d394-4bbd-a7d9-783e02c4fa60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T00:25:01.334127Z",
     "iopub.status.busy": "2023-09-24T00:25:01.333394Z",
     "iopub.status.idle": "2023-09-24T00:25:01.340831Z",
     "shell.execute_reply": "2023-09-24T00:25:01.340016Z",
     "shell.execute_reply.started": "2023-09-24T00:25:01.334097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {8: 0.009212053602095694,\n",
       "  128: 0.009397806506603957,\n",
       "  256: 0.010669440601486713,\n",
       "  512: 0.01914765270194039},\n",
       " 32: {8: 0.011300773499533534,\n",
       "  128: 0.13459614559542388,\n",
       "  256: 0.3646724847960286,\n",
       "  512: 0.7645334110944532},\n",
       " 64: {8: 0.018073088803794234,\n",
       "  128: 0.34874521840829403,\n",
       "  256: 0.7089315174962394,\n",
       "  512: 1.5779933413024991}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][MODEL_NAME]['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d7f164-c27c-4249-b024-d95d42d28141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T17:25:26.221761Z",
     "iopub.status.busy": "2023-09-24T17:25:26.220610Z",
     "iopub.status.idle": "2023-09-24T17:25:32.211846Z",
     "shell.execute_reply": "2023-09-24T17:25:32.209868Z",
     "shell.execute_reply.started": "2023-09-24T17:25:26.221707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting textpruner\n",
      "  Downloading textpruner-1.1.post2.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.0 in /usr/local/lib/python3.9/dist-packages (from textpruner) (4.21.3)\n",
      "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from textpruner) (1.12.1+cu116)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from textpruner) (4.64.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from textpruner) (0.1.97)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from textpruner) (3.19.6)\n",
      "Requirement already satisfied: numpy>1.17 in /usr/local/lib/python3.9/dist-packages (from textpruner) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->textpruner) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (2.28.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.0->textpruner) (0.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers>=4.0->textpruner) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.0->textpruner) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.0->textpruner) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers>=4.0->textpruner) (2019.11.28)\n",
      "Building wheels for collected packages: textpruner\n",
      "  Building wheel for textpruner (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for textpruner: filename=textpruner-1.1.post2-py3-none-any.whl size=43882 sha256=e862d3864095d3a7e9c6bbd52394634583335e362d16e3357c730291d2db6614\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/05/93/7ed7efba7071091691dd50709f6683955d609ff28324ac8710\n",
      "Successfully built textpruner\n",
      "Installing collected packages: textpruner\n",
      "Successfully installed textpruner-1.1.post2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install textpruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a32434cd-e090-430a-bb22-c2989e8d6515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:12:51.928333Z",
     "iopub.status.busy": "2023-09-24T18:12:51.927946Z",
     "iopub.status.idle": "2023-09-24T18:12:51.933803Z",
     "shell.execute_reply": "2023-09-24T18:12:51.932422Z",
     "shell.execute_reply.started": "2023-09-24T18:12:51.928305Z"
    }
   },
   "outputs": [],
   "source": [
    "from textpruner import PipelinePruner, TransformerPruningConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "356e38b4-d882-474d-9a08-8d3e111e9e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:14:03.473337Z",
     "iopub.status.busy": "2023-09-24T18:14:03.472799Z",
     "iopub.status.idle": "2023-09-24T18:14:03.480035Z",
     "shell.execute_reply": "2023-09-24T18:14:03.478604Z",
     "shell.execute_reply.started": "2023-09-24T18:14:03.473295Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer_pruning_config = TransformerPruningConfig(\n",
    "    target_ffn_size=2048,\n",
    "    target_num_of_heads=8, \n",
    "    pruning_method='iterative',\n",
    "    n_iters=4\n",
    ")\n",
    "\n",
    "pruner = PipelinePruner(model, tokenizer, transformer_pruning_config=transformer_pruning_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6eb2e2e-6254-44f3-841f-d14800f7bec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T18:14:03.482157Z",
     "iopub.status.busy": "2023-09-24T18:14:03.481812Z",
     "iopub.status.idle": "2023-09-24T19:03:57.665133Z",
     "shell.execute_reply": "2023-09-24T19:03:57.663868Z",
     "shell.execute_reply.started": "2023-09-24T18:14:03.482130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating IS with loss: 100%|██████████| 1250/1250 [12:27<00:00,  1.67it/s]\n",
      "Calculating IS with loss: 100%|██████████| 1250/1250 [12:25<00:00,  1.68it/s]\n",
      "Calculating IS with loss: 100%|██████████| 1250/1250 [12:26<00:00,  1.67it/s]\n",
      "Calculating IS with loss: 100%|██████████| 1250/1250 [12:26<00:00,  1.67it/s]\n",
      "100%|██████████| 40000/40000 [00:05<00:00, 7662.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New embedding size 29613 pruned vocab file has been saved to ./pruned_models/pruned_V29613H8.0F2048/vocab.txt. Reintialize the tokenizer!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./pruned_models/pruned_V29613H8.0F2048'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.prune(dataloader=pruning_dataloader, dataiter=dataset['question'][5000:45000], save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91ce89de-064c-4030-ab5c-b43a3a6545d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:05:21.302050Z",
     "iopub.status.busy": "2023-09-24T19:05:21.301633Z",
     "iopub.status.idle": "2023-09-24T19:05:21.314124Z",
     "shell.execute_reply": "2023-09-24T19:05:21.312291Z",
     "shell.execute_reply.started": "2023-09-24T19:05:21.302023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"Den4ikAI/ruBert-base-qa-ranker\",\n",
       "  \"architectures\": [\n",
       "    \"BertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 2048,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"problem_type\": \"single_label_classification\",\n",
       "  \"pruned_heads\": {\n",
       "    \"0\": [\n",
       "      1,\n",
       "      10,\n",
       "      4,\n",
       "      7\n",
       "    ],\n",
       "    \"1\": [\n",
       "      0,\n",
       "      9,\n",
       "      11,\n",
       "      6\n",
       "    ],\n",
       "    \"2\": [\n",
       "      0,\n",
       "      8,\n",
       "      10,\n",
       "      6\n",
       "    ],\n",
       "    \"3\": [\n",
       "      1,\n",
       "      10,\n",
       "      11,\n",
       "      6\n",
       "    ],\n",
       "    \"4\": [\n",
       "      8,\n",
       "      2,\n",
       "      3,\n",
       "      7\n",
       "    ],\n",
       "    \"5\": [\n",
       "      1,\n",
       "      10,\n",
       "      3,\n",
       "      9\n",
       "    ],\n",
       "    \"6\": [\n",
       "      9,\n",
       "      11,\n",
       "      5,\n",
       "      7\n",
       "    ],\n",
       "    \"7\": [\n",
       "      8,\n",
       "      11,\n",
       "      3,\n",
       "      6\n",
       "    ],\n",
       "    \"8\": [\n",
       "      0,\n",
       "      1,\n",
       "      3,\n",
       "      4\n",
       "    ],\n",
       "    \"9\": [\n",
       "      0,\n",
       "      1,\n",
       "      8,\n",
       "      7\n",
       "    ],\n",
       "    \"10\": [\n",
       "      0,\n",
       "      1,\n",
       "      10,\n",
       "      9\n",
       "    ],\n",
       "    \"11\": [\n",
       "      1,\n",
       "      2,\n",
       "      11,\n",
       "      7\n",
       "    ]\n",
       "  },\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.21.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 29613\n",
       "}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa32425-5b20-4e27-a8c2-8c48c9c9e46f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:22:37.118187Z",
     "iopub.status.busy": "2023-09-24T19:22:37.117677Z",
     "iopub.status.idle": "2023-09-24T19:22:41.066030Z",
     "shell.execute_reply": "2023-09-24T19:22:41.064177Z",
     "shell.execute_reply.started": "2023-09-24T19:22:37.118148Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './pruned_models/pruned_V29613H8.0F2048/'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f85bd0f2-b753-4364-9ffb-d3278bf7ddf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:11:52.467540Z",
     "iopub.status.busy": "2023-09-24T19:11:52.466588Z",
     "iopub.status.idle": "2023-09-24T19:11:56.899137Z",
     "shell.execute_reply": "2023-09-24T19:11:56.897926Z",
     "shell.execute_reply.started": "2023-09-24T19:11:52.467497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a5633bf69e4949836d97ef21bd3163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_test = dataset.select(indices=range(5000))\n",
    "dataset_test = dataset_test.map(tokenization, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e8294d3-1a93-47c6-b20f-75037a20cc0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:12:08.873016Z",
     "iopub.status.busy": "2023-09-24T19:12:08.872658Z",
     "iopub.status.idle": "2023-09-24T19:12:08.879816Z",
     "shell.execute_reply": "2023-09-24T19:12:08.878078Z",
     "shell.execute_reply.started": "2023-09-24T19:12:08.872990Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "729541a6-a6d8-4534-9a33-97567c6e0d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:12:37.171879Z",
     "iopub.status.busy": "2023-09-24T19:12:37.171352Z",
     "iopub.status.idle": "2023-09-24T19:12:37.177279Z",
     "shell.execute_reply": "2023-09-24T19:12:37.176407Z",
     "shell.execute_reply.started": "2023-09-24T19:12:37.171839Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bbd95b2-acc5-4a84-9c9f-291619b15e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:12:50.188262Z",
     "iopub.status.busy": "2023-09-24T19:12:50.187298Z",
     "iopub.status.idle": "2023-09-24T19:12:50.196074Z",
     "shell.execute_reply": "2023-09-24T19:12:50.192911Z",
     "shell.execute_reply.started": "2023-09-24T19:12:50.188216Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4058bd3-9408-4cbd-bdde-837d9aa2fef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:13:03.292954Z",
     "iopub.status.busy": "2023-09-24T19:13:03.292495Z",
     "iopub.status.idle": "2023-09-24T19:13:03.299795Z",
     "shell.execute_reply": "2023-09-24T19:13:03.297936Z",
     "shell.execute_reply.started": "2023-09-24T19:13:03.292918Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset_test, \n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa56aaae-7669-48cb-8ebe-2d5a45867c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:14:00.678184Z",
     "iopub.status.busy": "2023-09-24T19:14:00.677451Z",
     "iopub.status.idle": "2023-09-24T19:15:47.345614Z",
     "shell.execute_reply": "2023-09-24T19:15:47.344106Z",
     "shell.execute_reply.started": "2023-09-24T19:14:00.678156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6746ca3d6d194c5bbd4cbd295b3db868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc_score = evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "915e04f4-f046-4bab-a737-04958498a8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:16:29.476706Z",
     "iopub.status.busy": "2023-09-24T19:16:29.476119Z",
     "iopub.status.idle": "2023-09-24T19:16:29.484202Z",
     "shell.execute_reply": "2023-09-24T19:16:29.483125Z",
     "shell.execute_reply.started": "2023-09-24T19:16:29.476663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Area Under ROC Curve is 0.8927088349674912 after pruning\n"
     ]
    }
   ],
   "source": [
    "print(f'Dev Area Under ROC Curve is {roc_auc_score} after pruning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c93b61e2-6542-416e-aed6-43c481bbc12f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:18:07.898265Z",
     "iopub.status.busy": "2023-09-24T19:18:07.897759Z",
     "iopub.status.idle": "2023-09-24T19:18:08.588725Z",
     "shell.execute_reply": "2023-09-24T19:18:08.586967Z",
     "shell.execute_reply.started": "2023-09-24T19:18:07.898226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 321.895469\n"
     ]
    }
   ],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b524fd-c6ee-4852-9a98-6195ff033383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T19:23:19.239880Z",
     "iopub.status.busy": "2023-09-24T19:23:19.239296Z",
     "iopub.status.idle": "2023-09-24T19:26:39.079874Z",
     "shell.execute_reply": "2023-09-24T19:26:39.078728Z",
     "shell.execute_reply.started": "2023-09-24T19:23:19.239831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1\n",
      "\n",
      "====================       INFERENCE - SPEED - RESULT       ====================\n",
      "--------------------------------------------------------------------------------\n",
      "          Model Name             Batch Size     Seq Length     Time in s   \n",
      "--------------------------------------------------------------------------------\n",
      "./pruned_models/pruned_V29613H       1               8             0.013     \n",
      "./pruned_models/pruned_V29613H       1              128            0.014     \n",
      "./pruned_models/pruned_V29613H       1              256            0.013     \n",
      "./pruned_models/pruned_V29613H       1              512            0.013     \n",
      "./pruned_models/pruned_V29613H       32              8             0.015     \n",
      "./pruned_models/pruned_V29613H       32             128             0.08     \n",
      "./pruned_models/pruned_V29613H       32             256             0.21     \n",
      "./pruned_models/pruned_V29613H       32             512            0.393     \n",
      "./pruned_models/pruned_V29613H       64              8             0.014     \n",
      "./pruned_models/pruned_V29613H       64             128            0.198     \n",
      "./pruned_models/pruned_V29613H       64             256            0.355     \n",
      "./pruned_models/pruned_V29613H       64             512            0.801     \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================      INFERENCE - MEMORY - RESULT       ====================\n",
      "--------------------------------------------------------------------------------\n",
      "          Model Name             Batch Size     Seq Length    Memory in MB \n",
      "--------------------------------------------------------------------------------\n",
      "./pruned_models/pruned_V29613H       1               8              1161     \n",
      "./pruned_models/pruned_V29613H       1              128             1161     \n",
      "./pruned_models/pruned_V29613H       1              256             1161     \n",
      "./pruned_models/pruned_V29613H       1              512             1181     \n",
      "./pruned_models/pruned_V29613H       32              8              1183     \n",
      "./pruned_models/pruned_V29613H       32             128             1327     \n",
      "./pruned_models/pruned_V29613H       32             256             1567     \n",
      "./pruned_models/pruned_V29613H       32             512             2127     \n",
      "./pruned_models/pruned_V29613H       64              8              2127     \n",
      "./pruned_models/pruned_V29613H       64             128             2127     \n",
      "./pruned_models/pruned_V29613H       64             256             2127     \n",
      "./pruned_models/pruned_V29613H       64             512             3663     \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "benchmark_args = PyTorchBenchmarkArguments(\n",
    "    models=[MODEL_PATH],\n",
    "    training=False,\n",
    "    inference=True,\n",
    "    sequence_lengths=[8,128,256,512],\n",
    "    batch_sizes=[1,32,64],\n",
    "    multi_process=False,\n",
    "    cuda=True,\n",
    "    speed=True,\n",
    ")\n",
    "\n",
    "benchmark = PyTorchBenchmark(benchmark_args)\n",
    "results = benchmark.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1b1c4-413c-4cba-aeb7-e2ea74c480d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
